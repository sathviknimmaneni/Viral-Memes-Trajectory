{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ig.read('karate.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('soc-wiki-Vote.mtx',sep=' ',names = ['a','b'])\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "G = ig.Graph.TupleList(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## university email data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('email-univ.edges',sep=' ',names = ['a','b'])\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "G = ig.Graph.TupleList(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hamsterster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('soc-hamsterster.edges',sep=' ',names = ['a','b'])\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "G = ig.Graph.TupleList(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tvshow pages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fb-pages-tvshow.edges',sep=',',names = ['a','b'])\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "G = ig.Graph.TupleList(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('facebook_combined.txt',sep=' ',names = ['a','b'])\n",
    "\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "G = ig.Graph.TupleList(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Politician pages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fb-pages-politician.edges',sep=',',names = ['a','b'])\n",
    "tuples = [tuple(x) for x in df.values]\n",
    "G = ig.Graph.TupleList(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last.fm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('lastfm_asia_edges.csv',sep=',')\n",
    "\n",
    "tuples = [tuple(x) for x in test.values]\n",
    "G = ig.Graph.TupleList(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deezer europe network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('deezer_europe_edges.csv',sep=',')\n",
    "\n",
    "tuples = [tuple(x) for x in test.values]\n",
    "G = ig.Graph.TupleList(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-shell decompostion\n",
    "K = G.shell_index()\n",
    "G.vs['shell'] = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for x in G.vs.indices:\n",
    "    nodes.append(x)\n",
    "\n",
    "global_core = [x for x in nodes if K[x] == max(K)] #finding indices of network core elements\n",
    "global_core_name = [x['name'] for x in G.vs if x['shell'] == max(K)] # finds the list of node names in a network\n",
    "#[i for i in G.vs] # to understand what name of node means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding modulairty of the network\n",
    "clus = G.community_multilevel()\n",
    "G.modularity(clus.membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding number of communities in the network\n",
    "comm_count = 0\n",
    "for x in [i for i in G.community_multilevel()]:\n",
    "    comm_count += 1\n",
    "    for node in x:\n",
    "        G.vs[node]['community'] = comm_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding number of elements from each shell in a community\n",
    "count =0\n",
    "fData = dict()\n",
    "for num in range(1,comm_count+1): \n",
    "    data = dict()\n",
    "    count += 1\n",
    "    for i in [i for i in G.vs if i['community'] == num]:\n",
    "        data[i['shell']] = data.get(i['shell'], 0) + 1\n",
    "        fData[count] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find average shell number of a community\n",
    "def avg_shell(x):\n",
    "    sum_s=0\n",
    "    sum_w=0\n",
    "    for j in range(0,len(x)):\n",
    "        sum_s=sum_s+x[j][0]*x[j][1]\n",
    "        sum_w=sum_w+x[j][1]\n",
    "    return(sum_s/sum_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find standard deviation of shell number in a community\n",
    "def std_div(x):\n",
    "    deviations=0\n",
    "    sum_e=0\n",
    "    for i in range(0,len(x)):\n",
    "        deviations = deviations + (((x[i][0] - avg_shell(x)) ** 2)*x[i][1] )\n",
    "        sum_e=sum_e+x[i][1]\n",
    "    variance = deviations / sum_e\n",
    "    return((variance)**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find dispersion index of each commmunity\n",
    "def dispersion(x):\n",
    "    return(((std_div(x))**2)/avg_shell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find size of each community\n",
    "def com_size(x):\n",
    "    a=0\n",
    "    for i in range(0,len(x)):\n",
    "        a=a+x[i][1]\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntropy(i):\n",
    "    test = [j for i,j in fData[i].items()]\n",
    "    l = sum(test)\n",
    "    tmp = []\n",
    "    for i in test:\n",
    "        dum = i/l\n",
    "        tmp.append( dum * np.log2(dum))\n",
    "    return -sum(tmp)\n",
    "Entropy = [getEntropy(i) for i in range(1,comm_count+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfluence(commno):\n",
    "    tmp = []\n",
    "    for t in list(fData[commno].keys()):\n",
    "        tmp.append(len([i for i in G.vs.indices if K[i] == t]))\n",
    "\n",
    "    val = list(fData[commno].values())\n",
    "    shel = list(fData[commno].keys())\n",
    "\n",
    "    sumt= []\n",
    "    for i in range(len(tmp)):\n",
    "        sumt.append(shel[i]*val[i]/tmp[i])\n",
    "    return sum(sumt)\n",
    "Influence = [getInfluence(i) for i in range(1,comm_count+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(1,len(fData)+1):\n",
    "    od = collections.OrderedDict(sorted(fData[i].items()))#sorts the data of shell distribution in a community which is stored in fData w.r.t the shell number for each community \n",
    "    od = list(od.items())\n",
    "    data.append([i,com_size(od),avg_shell(od),std_div(od),dispersion(od)])\n",
    "d = pd.DataFrame(data,columns=[\"comm_no\",\"comm_size\",\"mean\",\"std_dev\",\"dispersion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding entropy to the dataframe\n",
    "d['Entropy'] = Entropy\n",
    "d['Influence'] = Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the data frame with respective to the community size(ascending order).\n",
    "d.sort_values('comm_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.to_excel('Results_dr.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Comparison between most influential and largest communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_num1 = 13 #values change for each data set\n",
    "comm_num2 = 4 #values change for each data set\n",
    "od_1 = collections.OrderedDict(sorted(fData[comm_num1].items())) #sorts the data by shell numbers for community 1\n",
    "od_2 = collections.OrderedDict(sorted(fData[comm_num2].items())) #sorts the data by shell numbers for community 2\n",
    "\n",
    "X1 = list(od_1.keys()) #shell numbers of first community\n",
    "X2 = list(od_2.keys()) #shell numbers of second community\n",
    "Y1 = list(od_1.values())#number of nodes in each shell for first community\n",
    "Y2 = list(od_2.values())#number of nodes in each shell for second community\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('Shell Number')\n",
    "plt.ylabel('Number of Nodes')\n",
    "plt.plot(X1,Y1,label='Community_13')\n",
    "plt.plot(X2,Y2,label='Community_4')\n",
    "plt.legend()\n",
    "plt.savefig('NodesinEachShell_Comapre.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Correlation of Shell Number and Fraction of nodes present in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlot(fData,i):\n",
    "    od = collections.OrderedDict(sorted(fData[i].items())) #sorts the data by shell numbers for each community\n",
    "    od = list(od.items())\n",
    "    \n",
    "    shell_len = dict()\n",
    "    for k in list(set(K)): #finds the size of each shell\n",
    "        shell_len[k] = len([i for i in G.vs if i['shell'] == k]) \n",
    "    \n",
    "    r=[]\n",
    "    for i in range(0,len(od)): # finds the fraction of nodes present in each shell in a community with respective to the netwwork\n",
    "        r.append([od[i][0],(od[i][1])/shell_len[od[i][0]]])\n",
    "        \n",
    "    tmp = [i for i,j in r if j == 1]\n",
    "    R = [(i,j) for i,j in r if i not in tmp] #ignores the shell with only one node\n",
    "    \n",
    "    x = [i for i,j in R] # shell number \n",
    "    y = [j for i,j in R] # fraction of nodes present in shell number\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.xticks(x,rotation=90)\n",
    "    plt.xlabel('Shell Number')\n",
    "    plt.ylabel('Fraction of nodes present')\n",
    "#     plt.show()\n",
    "    p = plt.plot(x,y)\n",
    "    plt.savefig('test.{}.jpg'.format(i))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPlot(fData,4) #change the number to get plot for each community "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Entropy and mean shell distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(d['Entropy'])\n",
    "Y = list(d['mean'])\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.scatter(X,Y)\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Weighted Mean')\n",
    "plt.savefig('EntropyVSMeanShell_deezer.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Entropy and influence measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = list(d['comm_no'])\n",
    "X = list(d['Entropy'])\n",
    "A = list(d['Influence'])\n",
    "A = [i*10 for i in A]\n",
    "colors = np.random.rand(comm_count)\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(X,Y,s=A,c=colors,alpha=0.5)\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Community Number')\n",
    "plt.savefig('EntropyVSCommno_Dezzer.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Global core and Local core properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to find interstion between two sets\n",
    "def common_elements(a,b):\n",
    "    a.sort()\n",
    "    b.sort()\n",
    "    i,j=0,0\n",
    "    intersection=[ ]\n",
    "    while i<len(a) and j<len(b):\n",
    "        if a[i] == b[j]:\n",
    "            intersection.append(a[i])\n",
    "            i=i+1\n",
    "            j=j+1\n",
    "        elif a[i]<b[j]:\n",
    "            i=i+1\n",
    "        else:\n",
    "            j=j+1\n",
    "    return(len(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = []\n",
    "for i in range(0,comm_count):\n",
    "    G_comm = G.subgraph(G.community_multilevel()[i]) #subgraphs each community and stores in a new variable\n",
    "    K_local = G_comm.shell_index() #finds nodes shell number w.r.t to new subgraph\n",
    "    nodes_local = []\n",
    "    for x in G_comm.vs: #finds the nodes indices w.r.t to new subgrpah\n",
    "        nodes_local.append(x)\n",
    "    local_core = [x['name'] for x in nodes_local if K_local[x.index] == max(K_local)] #finds the local of each community\n",
    "    U = len(global_core_name)\n",
    "    V = len(local_core)\n",
    "    intersection = common_elements(global_core_name,local_core)\n",
    "    union = U + V - intersection\n",
    "    jaccard.append(intersection/union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_of_community_nodes_in_local_core=[]\n",
    "fraction_of_community_nodes_in_gobal_core=[]\n",
    "fraction_of_global_core_in_local_core=[]\n",
    "fraction_of_local_core_in_global_core=[]\n",
    "\n",
    "for i in range(0,comm_count):\n",
    "    G_comm = G.subgraph(G.community_multilevel()[i]) #subgraphs each community and stores it in G_comm\n",
    "    K_local = G_comm.shell_index() \n",
    "    G_comm.vs['shell'] = K_local #finds nodes shell number w.r.t to new subgraph\n",
    "    nodes_local = []\n",
    "    for y in G_comm.vs.indices:#finds the nodes indices w.r.t to new subgrpah\n",
    "        nodes_local.append(y) \n",
    "    local_core = [G.community_multilevel()[i][x] for x in nodes_local if K_local[x] == max(K_local)] #finds the local of each community\n",
    "    fraction_of_community_nodes_in_local_core.append(round(len(local_core)/len(G.community_multilevel()[i]),3)) #fraction of community nodes in local core\n",
    "    fraction_of_community_nodes_in_gobal_core.append(round(len(list(set(G.community_multilevel()[i]).intersection(global_core)))/len(G.community_multilevel()[i]),3)) #fraction of community nodes in gobal core\n",
    "    fraction_of_global_core_in_local_core.append(round(len(list(set(local_core).intersection(global_core)))/len(global_core),3)) #fraction of global core in local core\n",
    "    fraction_of_local_core_in_global_core.append(round(len(list(set(local_core).intersection(global_core)))/len(local_core),3)) #fraction of local core in global core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(0,comm_count):    \n",
    "    data.append([jaccard[i],fraction_of_community_nodes_in_local_core[i],fraction_of_community_nodes_in_gobal_core[i],fraction_of_global_core_in_local_core[i],fraction_of_local_core_in_global_core[i]])     \n",
    "d = pd.DataFrame(data,columns=[\"jaccard\",\"fract_comm_local\",\"fract_comm_gobal\",\"fract_global_local\",\"fract_local_global\"])\n",
    "d.to_excel('task2_deezer.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
